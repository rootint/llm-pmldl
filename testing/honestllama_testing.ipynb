{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e2820c2-dd95-403e-bc39-18c3ca4259eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T11:57:10.287610Z",
     "iopub.status.busy": "2023-11-28T11:57:10.287208Z",
     "iopub.status.idle": "2023-11-28T11:57:25.858089Z",
     "shell.execute_reply": "2023-11-28T11:57:25.857292Z",
     "shell.execute_reply.started": "2023-11-28T11:57:10.287586Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, torch, logging\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments, pipeline\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "import transformers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ad56ee-ee33-4862-aa4a-a0c62b3e5e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T11:57:48.727320Z",
     "iopub.status.busy": "2023-11-28T11:57:48.726969Z",
     "iopub.status.idle": "2023-11-28T11:57:48.752814Z",
     "shell.execute_reply": "2023-11-28T11:57:48.752293Z",
     "shell.execute_reply.started": "2023-11-28T11:57:48.727297Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the key challenge with full fine-tunin...</td>\n",
       "      <td>Full fine-tuning of large models like GPT-3, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Low-Rank Adaptation (LoRA)?</td>\n",
       "      <td>LoRA is a method that freezes the pre-trained ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does LoRA compare to full fine-tuning in t...</td>\n",
       "      <td>LoRA can reduce the number of trainable parame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the impact of LoRA on inference latency?</td>\n",
       "      <td>LoRA introduces no additional inference latenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can LoRA be combined with other adaptation met...</td>\n",
       "      <td>Yes, LoRA is orthogonal to many prior methods ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question                                             Answer\n",
       "0  What is the key challenge with full fine-tunin...  Full fine-tuning of large models like GPT-3, w...\n",
       "1                What is Low-Rank Adaptation (LoRA)?  LoRA is a method that freezes the pre-trained ...\n",
       "2  How does LoRA compare to full fine-tuning in t...  LoRA can reduce the number of trainable parame...\n",
       "3   What is the impact of LoRA on inference latency?  LoRA introduces no additional inference latenc...\n",
       "4  Can LoRA be combined with other adaptation met...  Yes, LoRA is orthogonal to many prior methods ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('final_data1.tsv', sep=\"\\t\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e111cb-cb31-4d85-b451-c0481e9b5552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T11:57:51.053249Z",
     "iopub.status.busy": "2023-11-28T11:57:51.052930Z",
     "iopub.status.idle": "2023-11-28T11:57:51.083295Z",
     "shell.execute_reply": "2023-11-28T11:57:51.082773Z",
     "shell.execute_reply.started": "2023-11-28T11:57:51.053229Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"<s>[INST] Answer the following question: \"\n",
    "data[\"text\"] = (\n",
    "    instruction + data[\"Question\"] + \"[/INST] \" + data[\"Answer\"] + \" </s>\"\n",
    ")\n",
    "\n",
    "# Drop other columns so that only the 'text' column remains\n",
    "data = data[[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b41b4c9-836c-4625-b511-073ac611872b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T11:57:53.827036Z",
     "iopub.status.busy": "2023-11-28T11:57:53.826728Z",
     "iopub.status.idle": "2023-11-28T11:57:53.862886Z",
     "shell.execute_reply": "2023-11-28T11:57:53.862268Z",
     "shell.execute_reply.started": "2023-11-28T11:57:53.827018Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "training_data = Dataset(pa.Table.from_pandas(data.reset_index(drop=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d64c1-9ce6-4e42-a792-eaa35c03c91a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T11:57:56.284311Z",
     "iopub.status.busy": "2023-11-28T11:57:56.283656Z",
     "iopub.status.idle": "2023-11-28T12:05:57.552968Z",
     "shell.execute_reply": "2023-11-28T12:05:57.552167Z",
     "shell.execute_reply.started": "2023-11-28T11:57:56.284288Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model and tokenizer names\n",
    "base_model_name = \"likenneth/honest_llama2_chat_7B\"\n",
    "refined_model = \"honest-llama-neuralearn-qlora-ft\"\n",
    "\n",
    "# Tokenizer\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_tokenizer.padding_side = \"right\"  # Fix for fp16\n",
    "\n",
    "# Quantization Config\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "\n",
    "quant_8bits = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    ")\n",
    "\n",
    "# Model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "base_model.config.use_cache = False\n",
    "base_model.config.pretraining_tp = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
